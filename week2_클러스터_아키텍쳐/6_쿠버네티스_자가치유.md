# 6. 쿠버네티스 자가 치유
쿠버네티스의 핵심 기능으로, 사용자가 선언한 **'원하는 상태(Desired State)'**와 시스템의 **'현재 상태(Current State)'**를 지속적으로 비교함. 두 상태 간의 불일치(Drift) 감지 시, 시스템이 자동으로 '원하는 상태'로 복구 조치를 실행하는 메커니즘.
> **목적:** 장애 발생 시 수동 개입을 최소화하고, 서비스 고가용성(High Availability) 및 시스템 복원력(Resilience)을 확보하는 데 있음.
    


## 6.1. 핵심 작동 원리: 컨트롤 루프 (Control Loop)

컨트롤 플레인(특히 `kube-controller-manager`)에서 실행되는 **'컨트롤 루프(또는 조정 루프)'**.
    
- **주요 순환 단계**
    
    1. **관찰 (Observe):** API 서버를 통해 클러스터의 '현재 상태'를 실시간 파악함.
        
    2. **비교 (Compare):** '원하는 상태'(YAML 정의)와 '현재 상태'를 비교하여 차이를 감지함.
        
    3. **조치 (Act):** 감지된 차이를 해소하기 위한 자동화된 복구 작업(예: 파드 생성)을 수행함.
        
- 상기 `관찰 -> 비교 -> 조치` 과정을 무한 반복하며 시스템의 항상성을 유지함.
    


## 6.2. 장애 시나리오별 자가 치유 상세

### 6.2.1. 컨테이너 레벨 장애 (애플리케이션 응답 없음)

**진단:** 각 노드의 `kubelet`이 **`Liveness Probe(활성 프로브)`**를 통해 컨테이너의 비정상 상태를 감지.


**조치:** 장애가 발생한 특정 컨테이너를 즉시 **재시작(Restart)**하여 서비스 복구.
    
	 
### 6.2.2. 파드(Pod) 레벨 장애 (파드 비정상 종료)

**진단:** **`ReplicaSet` 컨트롤러**가 '원하는' 파드 개수 대비 '현재' 실행 중인 파드 개수의 부족을 인지.


**조치:** 부족한 수량만큼의 신규 파드를 **재생성(Re-creation)**하여 '원하는 상태'의 개수를 보장.


### 6.2.3.  노드(Node) 레벨 장애 (서버 다운)
    
**진단:** 컨트롤 플레인의 **`Node Controller`**가 특정 노드의 'Heartbeat(심박)' 신호 중단을 감지, 해당 노드를 '비정상(NotReady)' 상태로 판별.


**조치:** 장애 노드에서 실행되던 파드들을 클러스터 내 타 가용 노드(Healthy Node)로 **재배치(Rescheduling)**하여 서비스 연속성을 확보.
