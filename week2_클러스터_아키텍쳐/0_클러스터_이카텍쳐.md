# 클러스터 아키텍쳐

<aside>

쿠버네티스 뒤편의 구조와 설계 개념들에 대해 알아본다.

- 이 문서는 쿠버네티스 클러스터를 구성하기 위해 필요한 다양한 컴포넌트를 설명한다.
</aside>

&nbsp;

쿠버네티스는 Ch1(쿠버네티스란 무엇인가?)에서 언급한 바와 같이 컨트롤 플레인과 노드라고 불리는 일련의 워커 머신으로 구성되어 있다.

이 노드는 각각의 컨테이너화된 애플리케이션을 실행한다.

&nbsp;

모든 클러스터는 파드를 실행하기 위해 최소한 하나의 워커 노드가 필요하다.

워커 노드는 애플리케이션 워크로드의 구성 요소인 파드를 호스팅한다.

→ 애플리케이션 워크로드: 서비스, 프로그램 전체

→ 파드: 프론트엔드, 백엔드 API, DB.. 에 각각 1개씩 할당

- 워크로드란?
  - 쿠버네티스에서 실행되는 애플리케이션이나 작업
  - etc: 웹 서버 어플리케이션, DB, API 서버..
  - “워크로드를 실행한다” → “애플리케이션을 돌린다”
- 호스팅?
  - **호스팅**은 프로그램이나 애플리케이션을 **실행할 수 있는 환경을 제공**하는 것

→ 워커 노드가 파드를 호스팅한다 = 워커 노드가 파드를 자기 안에서 실행시킨다라고 보면 된다.

&nbsp;

컨트롤 플레인은 클러스터 내의 워커 노드와 파드를 관리한다.

프로덕션 환경에서, 컨트롤 플레인은 보통 여러 대의 컴퓨터에서 실행된다.

- **왜?**

  1.장애 대비(고가용성)

  - 컨트롤 플레인이 1대만 있으면, 그 컴퓨터가 고장나면 전체 클러스터 관리가 불가능
  - 여러 대에 분산하면, 하나가 고장나도 다른 것이 계속 작동

  2. 부하 분산

  - 대규모 클러스터에서는 관리 작업도 많아짐
  - 여러 컴퓨터가 나눠서 처리하면 효율적

&nbsp;

클러스터는 일반적으로 여러 개의 노드를 실행하여, 장애 허용성과 고가용성을 제공한다.

- How?
  - **복제 (Replication)**
    - 같은 애플리케이션을 여러 노드에 복사해서 실행
    - 예: 웹 서버 파드를 3개 노드에 각각 1개씩 배치
  - **자동 복구 (Self-healing)**
    - 노드 A가 고장나면, 쿠버네티스가 자동으로 노드 B에 파드를 새로 생성
    - 사용자는 서비스 중단을 거의 느끼지 못함
  - **로드 밸런싱**
    - 트래픽을 여러 노드에 분산
    - 한 노드에 부하가 집중되지 않도록 관리

---

### **쿠버네티스 클러스터 컴포넌트**

<aside>

아래 그림은 쿠버네티스 클러스터에 대한 예시 참조 아키텍쳐를 나타낸다.

- 실제 분포는 특정 클러스터의 설정과 요구사항에 따라 달라질 수 있다.
</aside>

![alt text](./img/image0_1.png)

다이어그램에서, 각 노드(Node 1, Node 2)는 [`kube-proxy`](https://kubernetes.io/ko/docs/concepts/architecture/#kube-proxy) 컴포넌트를 실행한다.

- 클러스터 네트워크에서 서비스 API와 관련 동작을 사용할 수 있도록 각 노드에는 네트워크 프록시 컴포넌트가 필요하다.
- 그러나, 일부 네트워크 플러그인은 자체 서드파티 프록시 구현을 제공한다.
  - 그러한 네트워크 플러그인을 사용할 경우, 해당 노드에서 `kube-proxy` 를 실행할 필요가 없다.

---

### 컨트롤 플레인 컴포넌트

-> 회사의 경영진처럼 전체적인 결정을 내리고 관리하는 부분이라고 보자.

</aside>

클러스터에 대한 전역적인 결정(etc: 스케줄링)뿐만 아니라, 클러스터의 이벤트를 감지하고 대응한다.

→ 예를 들어, deployment의 replica 필드가 충족되지 않을 때 파드를 새로 시작

컨트롤 플레인 컴포넌트는 클러스터 안의 어떤 머신에서도 실행될 수 있다.

- 그러나 설정 스크립트는 일반적으로 모든 컴포넌트를 동일한 머신에서 시작하며, 이 머신에서는 사용자 컨테이너를 실행하지 않는다.

여러 머신에 걸쳐 컨트롤 플레인을 실행하는 예시 설정은 [여기](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/)에서 참고한다.

&nbsp;

### kube-apiserver

<aside>

쿠버네티스의 정문 역할을 하며, 마치 회사의 접수 데스크처럼, 모든 요청을 받아서 처리한다.

- 즉, 모든 명령, 통신이 이곳을 통해 이뤄지고
- 여러 개를 실행해서 부하를 분산시킬 수도 있다.
</aside>

API 서버는 쿠버네티스 API를 노출하는 쿠버네티스 컨트롤 플레인 컴포넌트이다.

API 서버는 쿠버네티스 컨트롤 플레인의 프론트 엔드다.

쿠버네티스 API 서버의 주요 구현은 kube-apiserver이다.

kube-apiserver는 수평으로 확장되도록 디자인되었다.

- 즉, 더 많은 인스턴스를 배포해서 확장할 수 있다.
- 여러 kube-apiserver 인스턴스를 실행하고, 인스턴스간의 트래픽을 균형있게 조절할 수 있다.

&nbsp;

### etcd

모든 클러스터 데이터를 담는 쿠버네티스 뒷단의 저장소로 사용되는 일관성/고가용성 키-값 저장소이다.

쿠버네티스 클러스터에서 etcd를 뒷단의 저장소로 사용한다면, 이 데이터를 [백업](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster)하는 계획을 가져야 한다.

자세한 정보는 공식 [문서](https://etcd.io/docs)를 참고하자.

&nbsp;

### kube-scheduler

노드가 배정되지 않은 새로 생성된 파드를 감지하고, 실행할 노드를 선택하는 컨트롤 플레인 컴포넌트이다.

스케줄링 결정을 위해 고려되는 요소는 리소스에 대한 개별 및 총체적 요구 사항, 하드웨어/소프트웨어/정책적 제약, 어피니티(affinity)및 안티-어피티니 명세, 데이터 지역성, 워크로드-간 간섭, 데드라인을 포함한다.

- 어피니티? → 특정 조건의 노드를 선호하는지
- 데이터 지역성? → 데이터가 있는 곳 근처에 파드 배치
- 워크로드-간 간섭? → 파드끼리 서로 방해하지 않게 배치하기
- 데드라인? → 특정 시간까지 완료되어야 하는지 확인

&nbsp;

### kube-controller-manager

<aside>

여러 컨트롤러를 실행하여 클러스터 상태를 관리하는 관리자다.

</aside>

컨트롤러 프로세스를 실행하는 컨트롤 플레인 컴포넌트이다.

논리적으로, 각 컨트롤러는 분리된 프로세스이지만, 복잡성을 낮추기 위해 모두 단일 바이너리로 컴파일되고 단일 프로세스 내에서 실행된다.

- 모든 컨트롤러를 하나의 바이너리로 컴파일 → 하나의 프로세스로 실행한다.

컨트롤러에는 여러 가지 유형이 있다.

- 예시의 일부이다.
  - 노드 컨트롤러(Node Controller): 노드가 다운될 때 이를 감지하고 대응한다.
  - 잡 컨트롤러(Job Controller): 일회성 작업을 나타내는 잡(Job) 오브젝트를 감시하고, 해당 작업을 수행하기 위한 파드를 생성한다.
  - 엔드포인트슬라이스 컨트롤러(EndpointSlice controller): 엔드포인트슬라이스 오브젝트를 채워서 파드와 서비스 사이의 연결을 제공한다.
  - 서비스어카운트 컨트롤러(ServiceAccount controller): 신규 네임스페이스에 기본 서비스어카운트를 생성한다.

&nbsp;

### 클라우드 컨트롤 매니저

<aside>

클라우드 서비스와 연동하는 역할로, AWS, GCP같은 클라우드와 통신하는 통역사라고 볼 수 있다.

- 클라우드 로드밸런서 생성/관리
- 클라우드 스토리지 연결
- 노드가 클라우드에서 삭제되었는지 확인
</aside>

클라우드별 컨트롤 로직을 포함하는 쿠버네티스 [컨트롤 플레인](https://kubernetes.io/ko/docs/reference/glossary/?all=true#term-control-plane) 컴포넌트이다.

클라우드 컨트롤러 매니저를 통해 클러스터를 클라우드 공급자의 API에 연결하고, 해당 클라우드 플랫폼과 상호 작용하는 컴포넌트와 클러스터와만 상호 작용하는 컴포넌트를 구분할 수 있게 해준다.

클라우드 컨트롤러 매니저는 오직 클라우드 공급자에 특화된 컨트롤러만 실행한다.

- 쿠버네티스를 온프레미스 환경이나, 개인 PC의 학습환경에서 실행하는 경우, 클러스터에는 클라우드 컨트롤러 매니저가 없다.
  - 즉, minikube로 하면… 없다.

kube-controller-manager와 마찬가지로, 클라우드 컨트롤러 매니저는 여러 개의 논리적으로 독립된 컨트롤 루프를 단일 바이너리로 결합하여 하나의 프로세스로 실행한다.

- 성능을 향상시키거나 장애 허용성을 높이기 위해 수평 확장(하나 이상의 복제본을 실행)할 수 있다.

다음과 같은 컨트롤러는 클라우드 공급자 의존성을 가질 수 있다.

- 클라우드 API가 필요한 경우
- 예시는 아래와 같다.

  - 노드 컨트롤러(Node controller): 노드가 응답을 멈춘 뒤 클라우드에서 해당 노드가 삭제되었는지를 판단하기 위해 클라우드 공급자를 확인한다.
  - 라우트 컨트롤러(Route controller): 클라우드 인프라스트럭처 기반에서 라우트를 설정한다.
  - 서비스 컨트롤러(Service controller): 클라우드 공급자의 로드 밸런서를 생성, 업데이트, 삭제한다.

    ```bash
    Service Controller (LoadBalancer 타입):
    - 로드밸런서 생성해라!

    AWS에서:
    → AWS API 호출 → ELB(Elastic Load Balancer) 생성

    GCP에서:
    → GCP API 호출 → Cloud Load Balancing 생성

    개인 PC(minikube)에서:
    → 클라우드 API 없음 → 로드밸런서 생성 불가! ❌

    → 클라우드 공급자에 의존!
    ```

---

### 노드 컴포넌트

<aside>

실제로 일(애플리케이션 실행)을 하는 워커 머신들 → 일꾼들!

</aside>

노드 컴포넌트는 모든 노드에서 실행되며, 실행 중인 파드를 유지하고 쿠버네티스 런타임 환경을 제공한다.

&nbsp;

### kubelet

클러스터의 각 노드에서 실행되는 에이전트다.

kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다.

다양한 메커니즘을 통해 제공된 파드 스펙(PodSpec)의 집합을 받아서 컨테이너가 해당 파드 스펙에 따라 건강하게 동작하는 것을 확실히 한다.

kubelet은 쿠버네티스를 통해 생성되지 않는 컨테이너는 관리하지 않는다.

&nbsp;

### kube-proxy (선택 사항)

<aside>

네트워크 통신을 관리하는 오브젝트로, 우체국처럼 패킷을 올바른 목적지로 전달하는 역할을 한다.

</aside>

kube-proxy는 클러스터의 각 [노드](https://kubernetes.io/ko/docs/concepts/architecture/nodes/)에서 실행되는 네트워크 프록시로, 쿠버네티스의 [서비스](https://kubernetes.io/ko/docs/concepts/services-networking/service/) 개념의 구현부이다.

- Service의 가상 IP를 실제 파드 IP로 변환해주는 핵심 컴포넌트
- kube-proxy가 없으면 Service가 작동하지 않음

kube-proxy는 노드의 네트워크 규칙을 유지 관리한다.

- **네트워크 규칙이란?**
  - "Service IP:Port → 파드 IP:Port" 매핑 규칙
  - 파드가 추가/삭제될 때마다 자동으로 규칙 업데이트

이 네트워크 규칙이 내부 네트워크 세션이나 클러스터 바깥에서 파드로 네트워크 통신을 할 수 있도록 해준다.

- **내부 통신**: 파드 ↔ 파드 (Service 이름으로 접근)
- **외부 통신**: 인터넷 → NodePort/LoadBalancer → 파드

kube-proxy는 운영 체제에 가용한 패킷 필터링 계층이 있는 경우, 이를 사용한다. 없다면, 트래픽 자체를 포워드(forward)한다.

- 패킷 필터링 계층
  - **iptables 모드**: 리눅스 iptables 규칙으로 패킷 변환 (기본값)
  - **IPVS 모드**: 더 빠른 로드밸런싱, 대규모 클러스터에 적합

서비스에 대한 패킷 포워딩을 자체적으로 구현하고, kube-proxy와 동등한 동작을 제공하는 네트워크 플러그인을 사용하는 경우, 클러스터 노드에서 kube-proxy를 실행할 필요가 없다.

&nbsp;

### 컨테이너 런타임

컨테이너 실행을 담당하는 소프트웨어이다.

쿠버네티스는 [containerd](https://containerd.io/docs/), [CRI-O](https://cri-o.io/#what-is-cri-o)와 같은 컨테이너 런타임 및 모든 [Kubernetes CRI (컨테이너 런타임 인터페이스)](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md) 구현체를 지원한다.

---

### 애드온

<aside>

클러스터에 추가 기능을 제공하는 선택적 구성 요소들.

- 기본 쿠버네티스 위에 올리는 `확장팩`같은 느낌.
</aside>

쿠버네티스 리소스(데몬셋(DaemonSet), 디플로이먼트(Deployment), 등)를 사용하여, 클러스터의 기능을 구현한다.

- 클러스터 수준의 기능을 제공하기 때문에, 애드온의 네임스페이스 리소스는 `kube-system` 네임스페이스에 속한다.

아래서 몇가지 예시를 보자.

&nbsp;

### DNS

다른 애드온들은 반드시 필요하지 않지만, 많은 예제가 이를 기반으로 하기에, 모든 클러스터에는 [클러스터 DNS](https://kubernetes.io/ko/docs/concepts/services-networking/dns-pod-service/)가 있어야 한다.

- **왜 필수인가?**
  - Service를 IP 주소 대신 이름으로 접근하려면 DNS 필요
  - 예: `http://backend-service` (이름) vs `http://10.96.100.50` (IP)
  - IP는 자주 바뀌지만 이름은 고정!

클러스터 DNS는 쿠버네티스 서비스에 대한 DNS 레코드를 제공하는 DNS 서버로, 사용자 환경에 있는 다른 DNS 서버와 별개로 동작한다.

- **DNS 레코드란?**
  - "이 이름은 이 IP다"라는 매핑 정보
  - 예: `backend-service.default.svc.cluster.local` → `10.96.100.50`
- 클러스터 DNS 동작
  ```bash
  파드: "backend-service에 접속하고 싶어!"
      ↓
  클러스터 DNS 조회: "backend-service = 10.96.100.50"
      ↓
  10.96.100.50으로 연결!
  ```

쿠버네티스에 의해 실행된 컨테이너는 자동으로 이 DNS 서버를 DNS 검색에 포함한다.

예시

```yaml
# frontend 파드에서 backend에 접근
apiVersion: v1
kind: Pod
metadata:
  name: frontend
spec:
  containers:
    - name: app
      image: myapp
      env:
        - name: BACKEND_URL
          value:
            "http://backend-service:80" # ← DNS 이름 사용!
            # IP 몰라도 됨!
```

&nbsp;

### 웹 UI (대시보드)

![alt text](./img/image0_2.png)

대시보드를 통해 사용자는 클러스터 자체 뿐만 아니라, 클러스터에서 실행중인 애플리케이션을 관리하고 문제를 해결할 수 있다.

&nbsp;

### 컨테이너 리소스 모니터링

[컨테이너 리소스 모니터링](https://kubernetes.io/ko/docs/tasks/debug/debug-cluster/resource-usage-monitoring/)은 컨테이너에 대한 일반적인 시계열 메트릭을 중앙 데이터베이스에 기록하고, 해당 데이터를 탐색할 수 있는 UI를 제공한다.

&nbsp;

### 클러스터 수준 로깅

[클러스터 수준 로깅](https://kubernetes.io/ko/docs/concepts/cluster-administration/logging/) 메커니즘은 컨테이너 로그를 검색/탐색 인터페이스를 갖춘 중앙 로그 저장소에 저장하는 역할을 한다.

&nbsp;

### 네트워크 플러그인

[네트워크 플러그인](https://kubernetes.io/ko/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins)은 컨테이너 네트워크 인터페이스(CNI) 사양을 구현하는 소프트웨어 컴포넌트이다. 이는 파드에 IP 주소를 할당하고 클러스터 내에서 서로 통신할 수 있도록 하는 역할을 한다.

---

### 아키텍쳐 변형

쿠버네티스의 핵심 컴포넌트는 일관성을 유지하지만, 배포되고 관리되는 방식은 달라질 수 있다.

이러한 변형을 이해하는 것은 특정 운영 요구 사항을 충족하는 쿠버네티스 클러스터를 설계하고 유지하는 데 매우 중요하다.

&nbsp;

### 컨트롤 플레인 배포 옵션

컨트롤러 플레인 컴포넌트는 여러 방식으로 배포될 수 있다.

<aside>

**전통적인 배포**

- 컨트롤 플레인 컴포넌트가 전용 머신이나 VM에서 직접적으로 실행되며, 보통 systemd 서비스로 관리된다.

**정적 파드**

- 컨트롤 플레인 컴포넌트가 정적 파드로 배포되며, 특정 노드의 kubelet에 의해 관리된다.
- 이는 kubeadm과 같은 도구에서 사용하는 일반적인 방식이다.
- minikube → 정적 파드 방식임.
  1. YAML 파일을 특정 폴더에 둠
     → /etc/kubernetes/manifests/kube-apiserver.yaml
  2. kubelet이 폴더 감시
     → "오, 새 파일 있네?"
  3. 자동으로 파드 실행
     → "API 서버 파드 시작!"
  4. 파일 삭제하면?
     → "파드 자동 종료!"

**셀프 호스팅(Self-hosted)**

- **컨트롤 플레인이 쿠버네티스 클러스터 자체 내에서 파드로 실행**되며, 디플로이드먼트와 스테이트풀셋 또는 다른 쿠버네티스 리소스에 의해 관리된다.

**매니지드 쿠버네티스 서비스(Managed Kubernetes services)**

- 클라우드 공급자는 종종 컨트롤 플레인을 추상화하여, 자사 서비스 제공의 일부로 컴포넌트를 관리해준다.
  - 사용자는 워커 노드만 신경쓰면 된다.
- 예시 - **AWS EKS**: Amazon이 컨트롤 플레인 관리 - **GCP GKE**: Google이 컨트롤 플레인 관리 - **Azure AKS**: Microsoft가 컨트롤 플레인 관리
</aside>

&nbsp;

### 워크로드 배치 고려사항

컨트롤 플레인 컨포넌트를 포함한 워크로드 배치는 클러스터의 크기, 성능 요구사항, 운영 정책에 따라 달라질 수 있다.

- 작은 규모의 클러스터나 개발용 클러스터에서는, 컨트롤 플레인 컴포넌트와 사용자 워크로드가 동일한 노드에서 실행될 수 있다.
- 대규모 프로덕션 클러스터에서는 보통 컨트롤 플레인 컴포넌트 전용 노드를 두어, 사용자 워크로드와 분리한다.
- 일부 조직은 중요한 애드온이나 모니터링 도구를 컨트롤 플레인에서 실행한다.

&nbsp;

### 클러스터 관리 도구

kubeadm, kops 그리고 Kubespray 같은 도구들은 클러스터를 배포하고 관리하는 데 서로 다른 접근 방식을 제공하며, 각 도구는 고유한 컴포넌트 배치 및 관리 방식을 가진다.

쿠버네티스 아키텍처의 유연성 덕분에 조직은 기능 복잡성, 성능, 그리고 관리 부담과 같은 요소들을 균형있게 고려하여 클러스터를 특정 요구사항에 맞게 조정할 수 있다.

&nbsp;

### 커스터마이제이션과 확장성

쿠버네티스 아키텍쳐는 다양한 커스터마이제이션을 허용한다.

- 기본 쿠버네티스 스케줄러와 함께 동작하거나 완전히 대체하기 위해 커스텀 스케줄러를 배포할 수 있다.
- API 서버는 커스텀리소스정의(CustomResourceDefinitions)와 API 집계를 통해 확장될 수 있다.
- 클라우드 공급자는 클라우드 컨트롤러 매니저를 사용하여 쿠버네티스와 긴밀하게 통합할 수 있다.

→ 클러스터를 특정 요구사항에 맞게 조정할 수 있다.
