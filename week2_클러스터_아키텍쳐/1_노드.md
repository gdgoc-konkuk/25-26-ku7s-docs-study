# 노드

쿠버네티스는 컨테이너를 파드내에 배치하고 노드에서 실행함으로써 워크로드를 구동한다.

- 워크로드란?
  - 쿠버네티스에서 실행되는 애플리케이션이나 작업

노드는 클러스터에 따라 가상 또는 물리적 머신일 수 있다.

각 노드는 컨트롤 플레인에 의해 관리되며 파드를 실행하는데 필요한 서비스를 포함한다.

노드의 컴포넌트에는 `kubelet`, `컨테이너 런타임` , `kube-proxy` 가 포함된다.

&nbsp;

### 관리

API 서버에 노드를 추가하는 두가지 주요 방법이 있다.

1. 노드의 kubelet으로 컨트롤 플레인에 자체 등록
2. 사용자(또는 다른 사용자)가 노드 오브젝트를 수동으로 추가

노드 오브젝트 또는 노드의 kubelet으로 자체 등록한 후 컨트롤 플레인은 새 노드 오브젝트가 유효한지 확인한다.

예로 아래의 JSON manifest에서 노드를 만드는 상황을 보자.

```yaml
{
  "kind": "Node",
  "apiVersion": "v1",
  "metadata":
    { "name": "10.240.79.157", "labels": { "name": "my-first-k8s-node" } },
}
```

쿠버네티스는 내부적으로 노드 오브젝트를 생성한다.(=표시한다)

쿠버네티스는 kubelet이 노드의 metadata.name필드와 일치하는 API 서버에 등록이 되어 있는지 확인한다.

노드가 정상이면(예를 들어 필요한 모든 서비스가 실행중인 경우) 파드를 실행할 수 있게 된다.

- 그렇지 않으면, 해당 노드는 정상이 될 때까지 모든 클러스터 활동에 대해 무시된다.

&nbsp;

<aside>

**참고**

- 쿠버네티스는 유효하지 않은 노드 오브젝트를 유지하고, 노드가 정상적인지 확인한다.
- 상태 확인을 중지하려면 사용자 또는 [컨트롤러](https://kubernetes.io/ko/docs/concepts/architecture/controller/)에서 노드 오브젝트를 명시적으로 삭제해야 한다.
</aside>

노드 오브젝트의 이름은 유효한 [DNS 서브도메인 이름](https://kubernetes.io/ko/docs/concepts/overview/working-with-objects/names/#dns-%EC%84%9C%EB%B8%8C%EB%8F%84%EB%A9%94%EC%9D%B8-%EC%9D%B4%EB%A6%84)이어야 한다.

- 예로 `node-1`, `worker-node-01.example.com` 같은 형식

&nbsp;

### 노드 이름 고유성

쿠버네티스는 같은 이름을 가진 노드를 같은 노드로 인식한다.

- 동시에 두 개의 노드가 같은 이름일 수 없다.
- 같은 이름이면 쿠버네티스는 “이 노드는 같은 상태와 설정을 가진 동일한 서버다”라고 가정한다.
- 서버를 업그레이드하거나 크게 변경할 때는 기존 노드를 API 서버에서 먼저 삭제한 후, 작업 완료 후 다시 등록해야 한다.

&nbsp;

### 노드에 대한 자체-등록(self-registration)

`kubelet` 플래그 `--register-node`가 참(기본값)일 경우, kubelet은 API 서버에 스스로 등록을 시도한다.

- 이는 대부분의 배포판에서 사용된다.

**자동 등록 시 사용하는 kubelet 옵션은 아래와 같다.**

- `--kubeconfig`
  - apiserver에 스스로 인증하기 위한 자격증명에 대한 경로.
- `--cloud-provider`
  - 자신에 대한 메타데이터를 읽기 위해 어떻게 클라우드 제공자와 소통할지에 대한 방법
- `--register-node`
  - 자동으로 API 서버에 등록
- `--register-with-taints`
  - 주어진 [테인트(taint)](https://kubernetes.io/ko/docs/concepts/scheduling-eviction/taint-and-toleration/) 리스트(콤마로 분리된 `<key>=<value>:<effect>`)를 가진 노드 등록.
  - `register-node`가 거짓이면 동작 안 함
- `--node-ip`
  - 선택적인, 쉼표로 구분된 노드의 IP 주소 리스트
  - 각 주소 체계마다 하나의 주소만 지정 가능
  - 지정하지 않으면 기본 IPv4 주소를 자동으로 사용
  - IPv4와 IPv6 각각 하나씩만 지정 가능
- `-node-labels`
  - 노드에 레이블(꼬리표)을 붙인다.
  - 예: `environment=production`, `disktype=ssd`
  - 나중에 특정 레이블을 가진 노드에만 파드를 배치할 수 있다.
- `--node-status-update-frequency`
  - 얼마나 자주 kubelet이 API 서버에 해당 노드 상태를 게시할 지 정의

&nbsp;

### **권한 관리**

- [Node authorization mode](https://kubernetes.io/docs/reference/access-authn-authz/node/)와 [NodeRestriction admission plugin](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#noderestriction)이 활성화 된다면
  - 각 kubelet은 자신이 속한 노드의 리소스에 대해서만 생성/수정할 권한을 가진다.
  - 다른 노드의 정보는 수정할 수 없어서 보안이 강화된다.

&nbsp;

**참고**

- 노드 설정을 변경할 때는 반드시 API 서버에서 노드를 삭제하고 다시 등록해야 한다.
  - kubelet을 새 설정(예: 새 레이블)으로 재시작해도, 같은 이름이면 변경사항이 적용되지 않는다.
  - 이미 실행 중인 파드들이 새 설정과 충돌하여 문제가 발생할 수 있다.
  - 예: 노드에 새 레이블을 추가했는데, 기존 파드는 그 레이블과 호환되지 않을 수 있다.
- 노드를 비우고(drain) 다시 등록하면 모든 파드가 적절하게 재배치된다.

&nbsp;

### 수동 노드 관리

`kubectl`을 사용해서 노드 오브젝트를 생성하고 수정할 수 있다.

노드 오브젝트를 수동으로 생성하려면 kubelet 플래그를 `--register-node=false` 로 설정한다.

이후 `kubectl` 명령어로 직접 노드 오브젝트를 생성하고 관리한다.

그래서 수동으로 뭘 할 수 있는데?

- **레이블 추가/변경**
  - 노드에 특성을 표시
  - 예: `kubectl label nodes node-1 disktype=ssd`
- **노드를 스케줄 불가로 표시 (Cordon)**
  ```bash
  kubectl cordon $NODENAME
  ```

<aside>

&nbsp;

**스케줄 불가 상태의 의미**:

- 새로운 파드가 이 노드에 배치되지 않음
- 하지만 이미 실행 중인 파드는 계속 실행
- **언제 사용?** 노드 재부팅, 유지보수 전에 사용
- 식당에서 "예약 마감" 표시를 걸면 새 손님은 못 들어오지만, 이미 식사 중인 손님은 계속 식사할 수 있는 것과 같음.
</aside>

보다 자세한 내용은 [안전하게 노드를 드레인(drain)하기](https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/) 를 참고

<aside>

&nbsp;

참고

- **DaemonSet**으로 배포된 파드는 예외 - 스케줄 불가 노드에서도 실행될 수 있다. - 이유: 로그 수집, 모니터링 같은 노드 필수 서비스이기 때문 - 예: 로그를 수집하는 파드는 노드가 유지보수 중이어도 계속 실행되어야 한다.
</aside>

&nbsp;

### 노드 상태

노드의 상태는 아래의 정보를 포함한다.

- 주소
- 컨디션
- 용량과 할당가능
- 정보

`kubectl`을 사용해서 노드 상태, 기타 세부 정보를 볼 수 있다.

```bash
kubectl descibe node <insert-node-name-here>
```

자세한 정보는 [노드 상태](https://kubernetes.io/ko/docs/reference/node/node-status/)를 참고

&nbsp;

### 노드 하트비트

<aside>

심장 박동으로, 노드가 살아있다고 주기적으로 신호를 보내는 것과 같다.

</aside>

**왜 필요하지?**

- 클러스터가 각 노드가 정상적으로 작동하는지 확인하기 위해
- 노드에 문제가 생기면 빠르게 대응하기 위해
- 병원에서 환자의 심박수를 모니터링하는 것과 같다.

**두 가지 형태의 하트비트**

- 노드의 `.status`업데이트
  - 노드의 현재 상태 정보를 업데이트하는 것
  - CPU/메모리 사용량, 디스크 상태, 네트워크 상태 등
- `kube-node-lease`네임스페이스 내의 Lease(리스) 오브젝트
  - 경량화된 하트비트 신호
  - 각 노드마다 하나의 리스 오브젝트를 가진다.
  - `.status` 업데이트보다 가볍고 빠름
  - 생존 신호만 보내는 것!

&nbsp;

### 노드 컨트롤러

<aside>

노드들을 감시하고 관리하는 “관리자”

- 쿠버네티스 컨트롤 플레인 컴포넌트
</aside>

**역할**

1. CIDR 블록 할당
   - CIDR? → Classless Inter-Domain Routing
     - IP 주소 범위를 할당하는 방식
     - 예: `10.244.1.0/24` (10.244.1.0 ~ 10.244.1.255 범위의 IP 주소)
   - 얘가 뭐하는데?
     - 노드가 새로 등록될 때, 해당 노드의 파드들이 사용할 IP 주소 범위를 할당
     - CIDR 할당 기능이 활성화된 경우에만 작동
   - 새 아파트 동이 생기면 관리 사무소가 각 동에 호수 번호 범위를 할당하는 것이라고 볼 수 있음
   - 각 노드의 파드들이 고유한 IP 주소를 가지도록 보장해, IP 주소 충돌을 방지함.
2. 노드 컨트롤러의 내부 노드 리스트를 클라우드 제공사업자의 사용 가능한 머신 리스트 정보를 근거로 최신상태로 유지하는 것
   - 자세히 말해 노드 컨트롤러 내부의 노드 리스트를 클라우드 제공사(AWS, GCP, Azure 등)의 실제 VM 리스트와 동기화
   - 노드가 불량상태일 때, 클라우드 제공사에게 “이 VM 아직 존재함?”라고 확인
   - VM이 삭제되었으면 노드 리스트에서도 제거
   - 퇴사한 직원이 있으면 명부에서 삭제하는 것이라고 볼 수 있음
3. 노드의 동작 상태 모니터링
   - 노드가 접근 불가능(Unreachable) 상태가 되는 경우
     - 노드의 `.status` 필드의 `Ready` 컨디션을 업데이트한다. 이 경우에는 노드 컨트롤러가 `Ready` 컨디션을 `Unknown`으로 설정
     - Ready 컨디션이란?
       - 노드의 상태를 나타내는 신호등 같은 것:
         - True: 노드 정상 (초록불 🟢)
         - False: 노드 문제 있음 (빨간불 🔴)
         - Unknown: 노드와 통신 안 됨 (깜빡이는 노란불 🟡)
   - 노드가 계속 접근 불가능 상태로 남아있는 경우
     - 해당 노드의 모든 파드에 대해서 [API를 이용한 축출](https://kubernetes.io/ko/docs/concepts/scheduling-eviction/api-eviction/)을 트리거한다.
     - 타임라인
       1. 노드가 `Unknown` 상태로 표시됨
       2. **5분 대기** (기본값)
       3. 여전히 응답 없으면 → 파드 축출 시작
       4. 파드들이 다른 정상 노드로 재배치됨
     - 파드 축출(Eviction)
       - 문제 있는 노드에서 파드를 강제로 제거하는 것
       - API를 통해 우아하게(gracefully) 종료를 시도
       - 다른 정상 노드에 파드를 다시 생성
       - 대피 → 이동 시키는 것
4. 주기적인 상태 체크

- 노드 컨트롤러는 **5초마다** 모든 노드의 상태를 확인
- 이 주기는 `kube-controller-manager`의 `-node-monitor-period` 플래그로 조정 가능

&nbsp;

### 축출 빈도 제한

<aside>

비상 상황에서 건물 대피 시, 모든 사람이 한꺼번에 나가면 혼란하다.

순차적으로 대피하는 것이 더 안전하다.

</aside>

대부분의 경우, 노드 컨트롤러는 초당 `--node-eviction-rate`(기본값 0.1)로 축출 속도를 제한

- 10초당 1개의 노드를 초과하여 파드 축출을 하지 않는다는 의미

노드 축출 행위는 주어진 **가용성 영역** 내 하나의 노드가 상태가 불량할 경우 변화

- 노드 컨트롤러는 영역 내 동시에 상태가 불량한 노드의 퍼센티지가 얼마나 되는지 체크
  - 상태가 불량한 노드의 비율이 최소 `-unhealthy-zone-threshold` (기본값 0.55)가 되면 축출 속도가 감소
  - 클러스터가 작으면 (즉 `-large-cluster-size-threshold` 노드 이하면 - 기본값 50) 축출이 중지.
  - 이외의 경우, 축출 속도는 초당 `-secondary-node-eviction-rate`(기본값 0.01)로 감소

왜 가용성 영역(AZ) 단위인가?

- 나머지가 연결되어 있는 동안 하나의 가용성 영역이 컨트롤 플레인으로부터 분할되어 질 수도 있기 때문
  - 한 영역이 컨트롤 플레인(관리 시스템)과 연결이 끊어져도 다른 영역은 정상 작동할 수 있음
  - 각 영역을 독립적으로 관리해야 전체 시스템 안정성 확보
- 클러스터가 여러 클라우드 제공사업자의 가용성 영역에 걸쳐 있지 않는 이상, 축출 매커니즘은 영역 별 가용성을 고려하지 않는다.

노드가 가용성 영역들에 걸쳐 퍼져 있는 주된 이유는

- 하나의 전체 영역이 장애가 발생할 경우 워크로드가 상태 양호한 영역으로 이전되어질 수 있도록 하기 위함
- 하나의 영역 내 모든 노드들이 상태가 불량하면 노드 컨트롤러는 `--node-eviction-rate` 의 정상 속도로 축출
  - 모든 영역이 완전히 상태불량(클러스터 내 양호한 노드가 없는 경우)한 경우는요?
    - 노드 컨트롤러는 컨트롤 플레인과 노드 간 연결에 문제가 있는 것으로 간주하고 축출을 실행하지 않는다.
    - 중단 이후 일부 노드가 다시 보이는 경우 노드 컨트롤러는 상태가 양호하지 않거나 접근이 불가능한 나머지 노드에서 파드를 축출한다.

노드 컨트롤러는 파드가 테인트를 허용하지 않을 때 `NoExecute`  테인트 상태의 노드에서 동작하는 파드에 대한 축출 책임도 가진다.

- **자동 테인트 추가**: 연결 불가/준비 안 됨 노드에 테인트 부여
- **스케줄링 차단**: 비정상 노드로 새 파드 배치 방지

→ 스케줄러가 비정상적인 노드에 파드를 배치하지 않게 된다.

[쿠버네티스 축출 정책 예시](https://www.notion.so/28ffcbb9109c80f98230d004eb9b6e0f?pvs=21)

&nbsp;

### 리소스 용량 추적

노드 오브젝트는 노드 리소스 용량에 대한 정보: 예를 들어, 사용 가능한 메모리의 양과 CPU의 수를 추적한다.

노드의 자체 등록은 등록하는 중에 용량을 보고한다.

수동으로 노드를 추가하는 경ㅇ 추가할 때 노드의 용량 정보를 설정해야 한다.

쿠버네티스 [스케줄러](https://kubernetes.io/ko/docs/reference/command-line-tools-reference/kube-scheduler/)는 노드 상에 모든 노드에 대해 충분한 리소스가 존재하도록 보장한다.

스케줄러는 노드 상에 컨테이너에 대한 요청의 합이 노드 용량보다 더 크지 않도록 체크한다.

- 요청의 합은 kubelet에서 관리하는 모든 컨테이너를 포함하지만
- 컨테이너 런타임에 의해 직접적으로 시작된 컨 테이너는 제외되고 kubelet의 컨트롤 범위 밖에서 실행되는 모든 프로세스도 제외된다.

&nbsp;

### 노드 토폴로지

`TopologyManager` [기능 게이트(feature gate)](https://kubernetes.io/ko/docs/reference/command-line-tools-reference/feature-gates/)를 활성화 시켜두면, kubelet이 리소스 할당 결정을 할 때 토폴로지 힌트를 사용할 수 있다.

- 토폴로지란?
  - 컴퓨터 하드웨어 구성요소들의 물리적 배치와 거리 관계
- 동작 방식은 아래와 같다.
  1. 파드 생성 요청
  2. TopologyManager 분석 (켜져있을 때)
  3. 최적 배치

자세한 내용은 [노드의 컨트롤 토폴로지 관리 정책](https://kubernetes.io/docs/tasks/administer-cluster/topology-manager/)을 본다.
